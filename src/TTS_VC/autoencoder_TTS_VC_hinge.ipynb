{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d85b869c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([416, 49])\n",
      "cccccccccccccccccc torch.Size([416, 49])\n",
      "torch.Size([466, 49])\n",
      "cccccccccccccccccc torch.Size([466, 49])\n",
      "torch.Size([565, 49])\n",
      "cccccccccccccccccc torch.Size([565, 49])\n",
      "torch.Size([173, 49])\n",
      "cccccccccccccccccc torch.Size([173, 49])\n",
      "torch.Size([815, 49])\n",
      "cccccccccccccccccc torch.Size([815, 49])\n",
      "torch.Size([1273, 49])\n",
      "cccccccccccccccccc torch.Size([1273, 49])\n",
      "torch.Size([239, 49])\n",
      "cccccccccccccccccc torch.Size([239, 49])\n",
      "torch.Size([639, 49])\n",
      "cccccccccccccccccc torch.Size([639, 49])\n",
      "torch.Size([1341, 49])\n",
      "cccccccccccccccccc torch.Size([1341, 49])\n",
      "torch.Size([1642, 49])\n",
      "cccccccccccccccccc torch.Size([1642, 49])\n",
      "torch.Size([174, 49])\n",
      "cccccccccccccccccc torch.Size([174, 49])\n",
      "torch.Size([622, 49])\n",
      "cccccccccccccccccc torch.Size([622, 49])\n",
      "torch.Size([234, 49])\n",
      "cccccccccccccccccc torch.Size([234, 49])\n",
      "torch.Size([371, 49])\n",
      "cccccccccccccccccc torch.Size([371, 49])\n",
      "torch.Size([1101, 49])\n",
      "cccccccccccccccccc torch.Size([1101, 49])\n",
      "torch.Size([344, 49])\n",
      "cccccccccccccccccc torch.Size([344, 49])\n",
      "torch.Size([397, 49])\n",
      "cccccccccccccccccc torch.Size([397, 49])\n",
      "torch.Size([514, 49])\n",
      "cccccccccccccccccc torch.Size([514, 49])\n",
      "torch.Size([292, 49])\n",
      "cccccccccccccccccc torch.Size([292, 49])\n",
      "torch.Size([284, 49])\n",
      "cccccccccccccccccc torch.Size([284, 49])\n",
      "torch.Size([809, 49])\n",
      "cccccccccccccccccc torch.Size([809, 49])\n",
      "torch.Size([1597, 49])\n",
      "cccccccccccccccccc torch.Size([1597, 49])\n",
      "torch.Size([498, 49])\n",
      "cccccccccccccccccc torch.Size([498, 49])\n",
      "torch.Size([528, 49])\n",
      "cccccccccccccccccc torch.Size([528, 49])\n",
      "torch.Size([1843, 49])\n",
      "cccccccccccccccccc torch.Size([1843, 49])\n",
      "torch.Size([1062, 49])\n",
      "cccccccccccccccccc torch.Size([1062, 49])\n",
      "torch.Size([456, 49])\n",
      "cccccccccccccccccc torch.Size([456, 49])\n",
      "torch.Size([638, 49])\n",
      "cccccccccccccccccc torch.Size([638, 49])\n",
      "torch.Size([646, 49])\n",
      "cccccccccccccccccc torch.Size([646, 49])\n",
      "torch.Size([972, 49])\n",
      "cccccccccccccccccc torch.Size([972, 49])\n",
      "torch.Size([509, 49])\n",
      "cccccccccccccccccc torch.Size([509, 49])\n",
      "torch.Size([313, 49])\n",
      "cccccccccccccccccc torch.Size([313, 49])\n",
      "torch.Size([675, 49])\n",
      "cccccccccccccccccc torch.Size([675, 49])\n",
      "torch.Size([356, 49])\n",
      "cccccccccccccccccc torch.Size([356, 49])\n",
      "torch.Size([339, 49])\n",
      "cccccccccccccccccc torch.Size([339, 49])\n",
      "torch.Size([555, 49])\n",
      "cccccccccccccccccc torch.Size([555, 49])\n",
      "torch.Size([2386, 49])\n",
      "cccccccccccccccccc torch.Size([2386, 49])\n",
      "torch.Size([1502, 49])\n",
      "cccccccccccccccccc torch.Size([1502, 49])\n",
      "torch.Size([848, 49])\n",
      "cccccccccccccccccc torch.Size([848, 49])\n",
      "torch.Size([839, 49])\n",
      "cccccccccccccccccc torch.Size([839, 49])\n",
      "torch.Size([563, 49])\n",
      "cccccccccccccccccc torch.Size([563, 49])\n",
      "torch.Size([273, 49])\n",
      "cccccccccccccccccc torch.Size([273, 49])\n",
      "torch.Size([296, 49])\n",
      "cccccccccccccccccc torch.Size([296, 49])\n",
      "torch.Size([603, 49])\n",
      "cccccccccccccccccc torch.Size([603, 49])\n",
      "torch.Size([310, 49])\n",
      "cccccccccccccccccc torch.Size([310, 49])\n",
      "torch.Size([728, 49])\n",
      "cccccccccccccccccc torch.Size([728, 49])\n",
      "torch.Size([519, 49])\n",
      "cccccccccccccccccc torch.Size([519, 49])\n",
      "torch.Size([1125, 49])\n",
      "cccccccccccccccccc torch.Size([1125, 49])\n",
      "phone_data 48\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "torch.Size([1, 2386, 49])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 1768, 14]             160\n",
      "              ReLU-2         [-1, 16, 1768, 14]               0\n",
      "            Conv2d-3           [-1, 32, 884, 7]           4,640\n",
      "              ReLU-4           [-1, 32, 884, 7]               0\n",
      "            Conv2d-5           [-1, 64, 878, 1]         100,416\n",
      "   ConvTranspose2d-6           [-1, 32, 884, 7]         100,384\n",
      "              ReLU-7           [-1, 32, 884, 7]               0\n",
      "   ConvTranspose2d-8         [-1, 16, 1768, 14]           4,624\n",
      "              ReLU-9         [-1, 16, 1768, 14]               0\n",
      "  ConvTranspose2d-10          [-1, 1, 3536, 28]             145\n",
      "          Sigmoid-11          [-1, 1, 3536, 28]               0\n",
      "================================================================\n",
      "Total params: 210,369\n",
      "Trainable params: 210,369\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.38\n",
      "Forward/backward pass size (MB): 20.07\n",
      "Params size (MB): 0.80\n",
      "Estimated Total Size (MB): 21.25\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_260772/3453719093.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_260772/3453719093.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3536\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m     optimizer = torch.optim.Adam(params=model.parameters(),\n\u001b[0m\u001b[1;32m    265\u001b[0m                                  \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                                  weight_decay=1e-5)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, validation_curve\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import codecs\n",
    "from torchsummary import summary\n",
    "# from torchshape import tensorshape\n",
    "from pprint import pprint\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "hyper = {\n",
    "    \"randomSeed\": 42,\n",
    "    \"nEpochs\":70,\n",
    "    \"PATH\": \"model.pt\",\n",
    "    \"batchSize\":8,\n",
    "    \"lr\":1e-3,\n",
    "    \"clip_grad\":0.1,\n",
    "\n",
    "}\n",
    "\n",
    "torch.manual_seed(hyper[\"randomSeed\"]);\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_binary_file(file_name, dimension):\n",
    "    fid_lab = open(file_name, 'rb')\n",
    "    features = np.fromfile(fid_lab, dtype=np.float32)\n",
    "    fid_lab.close()\n",
    "    assert features.size % float(dimension) == 0.0, 'specified dimension %s not compatible with data' % (dimension)\n",
    "    features = features[:(dimension * (features.size // dimension))]\n",
    "    features = features.reshape((-1, dimension))\n",
    "    return features\n",
    "\n",
    "def load_binary_file_frame(self, file_name, dimension):\n",
    "    fid_lab = open(file_name, 'rb')\n",
    "    features = numpy.fromfile(fid_lab, dtype=numpy.float32)\n",
    "    fid_lab.close()\n",
    "    assert features.size % float(dimension) == 0.0, 'specified dimension %s not compatible with data' % (dimension)\n",
    "    frame_number = features.size // dimension\n",
    "    features = features[:(dimension * frame_number)]\n",
    "    features = features.reshape((-1, dimension))\n",
    "\n",
    "    return features, frame_number\n",
    "\n",
    "\n",
    "\n",
    "dir_phonePath = \"/home/rania/Documents/workspace/tools/merlin/output\"\n",
    "dir_PPGpath = \"/home/rania/Documents/workspace/IntraSpkVC/data_fr/ppg/FFR0009\"\n",
    "phone_data = []\n",
    "PPG_data = []\n",
    "\n",
    "PPG_lengths = []\n",
    "phone_lengths = []\n",
    "\n",
    "\n",
    "def load_data(dir_path, x):\n",
    "    \n",
    "    file_list = glob.glob(dir_path + '/*.'+x+'')[:48]\n",
    "    \n",
    "    for idx, s in enumerate(file_list):\n",
    "        if x == 'flab':\n",
    "            data =torch.tensor(load_binary_file(s, 49))\n",
    "            print(data.shape)\n",
    "            data + torch.arange(2386)\n",
    "            print(\"cccccccccccccccccc\", data.shape)\n",
    "\n",
    "#           print(len(data[:,0]))\n",
    "            phone_data.append(data)\n",
    "            phone_lengths.append(len(data))\n",
    "        else:\n",
    "            data = np.load(s)\n",
    "            PPG_data.append(data)\n",
    "            PPG_lengths.append(len(data))\n",
    "\n",
    "    return phone_data, phone_lengths, PPG_data, PPG_lengths\n",
    "\n",
    "phone_data, phone_lengths, _, _ = load_data(dir_phonePath, 'flab')\n",
    "print(\"phone_data {}\".format(len(phone_data)  )    )\n",
    "\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.data = pad_sequence(data, batch_first=True, padding_value=0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx].clone().detach().requires_grad_(True)\n",
    "        x = torch.unsqueeze(x, 0)\n",
    "        return x  \n",
    "\n",
    "# _, _, PPG_data, PPG_lengths = load_data(dir_phonePath, 'npy')\n",
    "\n",
    "padded_phone = Dataset(phone_data)\n",
    "\n",
    "\n",
    "for i, item in enumerate(padded_phone):\n",
    "    print(item.shape)\n",
    "\n",
    "\n",
    "trainDataX, testDataX,trainDataY, testDataY = train_test_split([data for data in padded_phone ],[data for data in padded_phone ],test_size=0.2,random_state=41,shuffle=False,stratify=None)\n",
    "# print(\"size of the training dataset {}\".format(len(trainDataX)), trainDataX[2].shape)\n",
    "# print(\"size of the training dataset {}\".format(len(trainDataX)), trainDataX[3].shape)\n",
    "valDataX, testDataX, valDataY, testDataY = train_test_split(testDataX,testDataY,test_size=0.5,random_state=41,shuffle=False,stratify=None)\n",
    "# print(\"size of the validation dataset {}\".format(len(valDataX)), valDataY[0].shape)\n",
    "# print(\"size of the validation dataset {}\".format(len(valDataX)), valDataY[1].shape)\n",
    "\n",
    "def masking(data):\n",
    "    pad = 0\n",
    "    dataMask = (data == pad).type(torch.int16)\n",
    "    dataMask = 1 - dataMask\n",
    "    maskedData = torch.mul(dataMask, data)\n",
    "    return maskedData\n",
    "\n",
    "def train(trainLoader, model, criterion, optimizer,epoch =hyper[\"nEpochs\"]):\n",
    "    model.train()\n",
    "    totalLoss, batchNum = 0, 0\n",
    "    for i, trainData in enumerate(trainLoader):\n",
    "        trainData = Variable(trainData).to(device)\n",
    "        # ===================forward=====================\n",
    "        output = model(trainData)\n",
    "        loss = criterion(masking(output), trainData)\n",
    "        # print(loss)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        totalLoss += loss.item()\n",
    "        batchNum += 1\n",
    "    trainTotalCount = totalLoss / batchNum\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, epoch, trainTotalCount))\n",
    "    return trainTotalCount\n",
    "\n",
    "def valid(valLoader, model, criterion, epoch=hyper[\"nEpochs\"]):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        totalLoss, batchNum = 0, 0\n",
    "        for i, valData in enumerate(valLoader):\n",
    "            valData = Variable(valData).to(device)\n",
    "            # ===================forward=====================\n",
    "            output = model(valData)\n",
    "            loss = criterion(masking(output), valData)\n",
    "            totalLoss += loss.item()\n",
    "            batchNum += 1\n",
    "        ValTotalCount = totalLoss / batchNum\n",
    "    print('epoch [{}/{}], Validation loss:{:.4f}'.format(epoch + 1, epoch, ValTotalCount))\n",
    "    return ValTotalCount\n",
    "\n",
    "\n",
    "class SaveBestModel:\n",
    "    \"\"\"\n",
    "    Class to save the best model while training. If the current epoch's\n",
    "    validation loss is less than the previous least less, then save the\n",
    "    model state.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, bestValidLoss = float('inf')\n",
    "    ):\n",
    "        self.bestValidLoss = bestValidLoss\n",
    "\n",
    "    def __call__(\n",
    "            self, currentValidLoss,\n",
    "            epoch, model, optimizer, criterion\n",
    "    ):\n",
    "        if currentValidLoss < self.bestValidLoss:\n",
    "            self.bestValidLoss = currentValidLoss\n",
    "            print(f\"\\nBest validation loss: {self.bestValidLoss}\")\n",
    "            print(f\"\\nSaving best model for epoch: {epoch + 1}\\n\")\n",
    "            torch.save({\n",
    "                'epoch': hyper[\"nEpochs\"] + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': criterion,\n",
    "            }, 'outputs/best_model.pth')\n",
    "saveBestModel = SaveBestModel()\n",
    "\n",
    "def save_model(model, optimizer, criterion, epochs=hyper[\"nEpochs\"]):\n",
    "    \"\"\"\n",
    "    Function to save the trained model\n",
    "    \"\"\"\n",
    "    print(f\"Saving final model...\")\n",
    "    torch.save({\n",
    "        'epoch': epochs,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': criterion,\n",
    "    }, 'outputs/final_model.pth')\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),  # b, 16, 1768, 14\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),  # b,  32, 884, 7\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 7),  # b, 64, 878, 1\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 7),  # b, 32, 884, 7\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1,  output_padding=1),  # b, 16, 1768, 14\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),  # b, 1, 3536, 28\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def get_latent(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        y = self.decoder(x)\n",
    "        return x, y\n",
    "    \n",
    "def get_data_loaders(train_set, val_set):\n",
    "    \n",
    "    #load data loader\n",
    "    train_loader = DataLoader(\n",
    "        train_set, \n",
    "        batch_size=hyper[\"batchSize\"], \n",
    "        drop_last=False, \n",
    "        shuffle=True,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        val_set, \n",
    "        batch_size=hyper[\"batchSize\"], \n",
    "        drop_last=False, \n",
    "        shuffle=False,\n",
    "    )\n",
    "    return train_loader, test_loader\n",
    "\n",
    "trainLoader, valLoader = get_data_loaders(\n",
    "        trainDataX, \n",
    "        valDataX,\n",
    "\n",
    "    )\n",
    "\n",
    "def main():\n",
    "\n",
    "    # for i, data in enumerate(valLoader):\n",
    "    #     print('val ', data.shape)\n",
    "    model = Autoencoder().to(device)\n",
    "    model = summary(model, (1, 3536, 28))\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                                 lr=hyper[\"lr\"],\n",
    "                                 weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "\n",
    "    for epoch in range(hyper[\"nEpochs\"]):\n",
    "        print(f\"[INFO]: Epoch {epoch} of {hyper['nEpochs']}\")\n",
    "        # # ===================training========================\n",
    "        trainEpochLoss = train(trainLoader, model, criterion, optimizer, epoch)\n",
    "        # # ===================validation========================\n",
    "        validEpochLoss = valid(valLoader, model, criterion, epoch)\n",
    "        # # ===================checkpoints========================\n",
    "        trainLoss, validLoss = [], []\n",
    "        # start the training\n",
    "        trainLoss.append(trainEpochLoss)\n",
    "        validLoss.append(validEpochLoss)\n",
    "\n",
    "        print(f\"Training loss: {trainEpochLoss:.3f}\")\n",
    "        print(f\"Validation loss: {validEpochLoss:.3f}\")\n",
    "        # save the best model till now if we have the least loss in the current epoch\n",
    "        saveBestModel(\n",
    "            validEpochLoss, epoch, model, optimizer, criterion\n",
    "        )\n",
    "        # save the trained model weights for a final time\n",
    "        save_model(model, optimizer, criterion, epoch)\n",
    "        print('TRAINING COMPLETE')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b4a7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper = {\n",
    "    \"nEpochs\":100,\n",
    "    \"dimRNA\":dim_rna,\n",
    "    \"dimATAC\":dim_atac,\n",
    "    \"layer_sizes\":[1024, 512, 256],\n",
    "    \"nz\":128,\n",
    "    \"batchSize\":512,\n",
    "    \"lr\":1e-3,\n",
    "    \"add_hinge\":True,\n",
    "    \"lamb_hinge\":10,\n",
    "    \"lamb_match\":1,\n",
    "    \"lamb_nn\":1.5,\n",
    "    \"lamb_kl\":1e-9,\n",
    "    \"lamb_anc\":1e-9,\n",
    "    \"clip_grad\":0.1,\n",
    "    \"checkpoint_path\": './checkpoint/vae_hinge.pt',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ab98c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructureHingeLoss(nn.Module):\n",
    "    def __init__(self, margin, max_val, lamb_match, lamb_nn, device):\n",
    "        super(StructureHingeLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.max_val = max_val\n",
    "        self.lamb_match = lamb_match\n",
    "        self.lamb_nn = lamb_nn\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, rna_outputs, atac_outputs, nn_indices):\n",
    "        #rna_outputs: n_batch x n_latent\n",
    "        #atac_outputs: n_batch x n_latent\n",
    "        assert rna_outputs.shape[0] == atac_outputs.shape[0]\n",
    "        assert rna_outputs.shape[1] == atac_outputs.shape[1]\n",
    "        n_batch = rna_outputs.shape[0]\n",
    "        \n",
    "        #calculated pairwise L2 distance\n",
    "        #dist_rna_atac[i][j]: the L2 distance between RNA embedding i\n",
    "        #and ATAC embedding j (n_batch x n_batch)\n",
    "        #constraint for ensuring every rna embedding is close to matched atac embedding\n",
    "        dist_rna_atac = torch.cdist(rna_outputs, atac_outputs, p=2)\n",
    "        match_labels = torch.eye(n_batch).to(self.device)\n",
    "        match_mask = match_labels > 0\n",
    "        pos_match_dist = torch.masked_select(dist_rna_atac, match_mask).view(n_batch, 1)\n",
    "        neg_match_dist = torch.masked_select(dist_rna_atac, ~match_mask).view(n_batch, -1)\n",
    "        \n",
    "        loss_match_rna = torch.clamp(self.margin + pos_match_dist - neg_match_dist, 0, self.max_val)\n",
    "        loss_match_rna = loss_match_rna.mean()\n",
    "        #print(f\"loss_match_rna: {loss_match_rna}\")\n",
    "        \n",
    "        #constraint for ensuring every atac embedding is close to matched rna embedding\n",
    "        dist_atac_rna = dist_rna_atac.t()\n",
    "        pos_match_dist = torch.masked_select(dist_atac_rna, match_mask).view(n_batch, 1)\n",
    "        neg_match_dist = torch.masked_select(dist_atac_rna, ~match_mask).view(n_batch, -1)\n",
    "        \n",
    "        loss_match_atac = torch.clamp(self.margin + pos_match_dist - neg_match_dist, 0, self.max_val)\n",
    "        loss_match_atac = loss_match_rna.mean()\n",
    "        #print(f\"loss_match_atac: {loss_match_atac}\")\n",
    "        \n",
    "        #constraint for ensuring that every RNA embedding is close to \n",
    "        #the neighboring RNA embeddings.\n",
    "        nn_masked = torch.zeros(n_batch, n_batch).to(self.device)\n",
    "        nn_masked.scatter_(1, nn_indices, 1.)\n",
    "        nn_masked = nn_masked > 0\n",
    "        \n",
    "        dist_rna_rna = torch.cdist(rna_outputs, rna_outputs, p=2)\n",
    "        \n",
    "        #pos_rna_nn_dist: n_batch x n_neighbor\n",
    "        pos_rna_nn_dist = torch.masked_select(dist_rna_rna, nn_masked).view(n_batch, -1)\n",
    "        neg_rna_nn_dist = torch.masked_select(dist_rna_rna, ~nn_masked).view(n_batch, -1)\n",
    "        rna_nn_loss = torch.clamp(self.margin + pos_rna_nn_dist[...,None] - neg_rna_nn_dist[..., None, :], 0, self.max_val)\n",
    "        rna_nn_loss = rna_nn_loss.mean()\n",
    "        #print(f\"rna_nn_loss: {rna_nn_loss}\")\n",
    "        \n",
    "        #constraint for ensuring that every ATAC embedding is close to \n",
    "        #the neighboring ATAC embeddings.\n",
    "        dist_atac_atac = torch.cdist(atac_outputs, atac_outputs, p=2)\n",
    "        #pos_rna_nn_dist: n_batch x n_neighbor\n",
    "        pos_atac_nn_dist = torch.masked_select(dist_atac_atac, nn_masked).view(n_batch, -1)\n",
    "        neg_atac_nn_dist = torch.masked_select(dist_atac_atac, ~nn_masked).view(n_batch, -1)\n",
    "        atac_nn_loss = torch.clamp(self.margin + pos_atac_nn_dist[...,None] - neg_atac_nn_dist[..., None, :], 0, self.max_val)\n",
    "        atac_nn_loss = atac_nn_loss.mean()\n",
    "        #print(f\"atac_nn_loss: {atac_nn_loss}\")\n",
    "        \n",
    "        loss = (self.lamb_match * loss_match_rna \n",
    "                + self.lamb_match * loss_match_atac\n",
    "                + self.lamb_nn * rna_nn_loss \n",
    "                + self.lamb_nn * atac_nn_loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a370ed46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up loss function\n",
    "def basic_loss(recon_x, x, mu, logvar, lamb1):\n",
    "    MSE = nn.MSELoss()\n",
    "    lloss = MSE(recon_x, x)\n",
    "    #KL divergence\n",
    "    #KL_loss = -0.5*torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    #lloss = lloss + lamb1*KL_loss\n",
    "    return lloss\n",
    "\n",
    "#anchor loss for minimizing distance between paired observation\n",
    "def anchor_loss(embed_rna, embed_atac):\n",
    "    L1 = nn.L2Loss()\n",
    "    anc_loss = L2(embed_rna, embed_atac)\n",
    "    return anc_loss\n",
    "\n",
    "def hinge_loss(\n",
    "    margin, \n",
    "    max_val, \n",
    "    lamb_match,\n",
    "    lamb_nn, \n",
    "    embed_rna, \n",
    "    embed_atac, \n",
    "    nn_indices,\n",
    "):\n",
    "    Hinge_Loss = StructureHingeLoss(margin, max_val, lamb_match, lamb_nn)\n",
    "    loss = Hinge_Loss(embed_rna, embed_atac, nn_indices)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08362577",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataX, valDataX,trainDataY, valDataY = train_test_split([data for data in padded_phone ],[data for data in padded_phone ],test_size=0.2,random_state=41,shuffle=False,stratify=None)\n",
    "# print(\"size of the training dataset {}\".format(len(trainDataX)), trainDataX[2].shape)\n",
    "\n",
    "train_loader, test_loader = get_data_loaders(\n",
    "        trainDataX, \n",
    "        valDataX,\n",
    "        trainDataX,\n",
    "        valDataX,\n",
    "    )\n",
    "\n",
    "# print(train_loader, test_loader)\n",
    "# for i, item in enumerate(train_loader):\n",
    "#     print(item.shape)\n",
    "\n",
    "#load checkpoint\n",
    "checkpoint = None\n",
    "if path.exists(hyper[\"checkpoint_path\"]):\n",
    "    checkpoint = torch.load(hyper[\"checkpoint_path\"])\n",
    "\n",
    "\n",
    "#load basic models\n",
    "netPPG = Autoencoder()\n",
    "# netATAC = FC_VAE(n_input=hyper[\"dimATAC\"], nz=hyper[\"nz\"], layer_sizes=hyper[\"layer_sizes\"])\n",
    "if checkpoint != None:\n",
    "    netRNA.load_state_dict(checkpoint[\"PPG_state_dict\"])\n",
    "#     netATAC.load_state_dict(checkpoint[\"net_atac_state_dict\"])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"using GPU\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "netPPG.to(device)\n",
    "# netATAC.to(device)\n",
    "\n",
    "#setup optimizers for two nets\n",
    "opt_netPPG = optim.Adam(list(netPPG.parameters()), lr=hyper[\"lr\"])\n",
    "# opt_netATAC = optim.Adam(list(netATAC.parameters()), lr=hyper[\"lr\"])\n",
    "scheduler_netPPG = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    opt_netPPG,\n",
    "    patience=10,\n",
    "    threshold=0.01,\n",
    "    threshold_mode=\"abs\",\n",
    "    min_lr=1e-5,\n",
    ")\n",
    "# scheduler_netATAC = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#     opt_netATAC,\n",
    "#     patience=10,\n",
    "#     threshold=0.01,\n",
    "#     threshold_mode=\"abs\",\n",
    "#     min_lr=1e-5,\n",
    "# )\n",
    "\n",
    "best_knn_auc = 0\n",
    "if checkpoint != None:\n",
    "    best_knn_auc = checkpoint[\"dev_acc\"]\n",
    "\n",
    "#training\n",
    "for epoch in range(hyper[\"nEpochs\"]):\n",
    "    train_losses = []\n",
    "    #train for epochs\n",
    "    for idx, (data) in enumerate(train_loader):\n",
    "        \n",
    "        data = Variable(data).to(device)\n",
    "\n",
    "        opt_netPPG.zero_grad()\n",
    "#         opt_netRNA.zero_grad()\n",
    "        recon_PPG = netPPG(data)\n",
    "#         recon_atac, z_atac, mu_atac, logvar_atac = netATAC(atac_inputs_filtered)\n",
    "        ppg_loss = basic_loss(recon_PPG, data, 0, 0,0)\n",
    "#         atac_loss = basic_loss(recon_atac, aftac_inputs_filtered, mu_atac, logvar_atac, lamb1=hyper[\"lamb_kl\"])\n",
    "\n",
    "        if hyper[\"add_hinge\"]:\n",
    "            hinge_loss = StructureHingeLoss(\n",
    "                margin=0.3, \n",
    "                max_val=1e6, \n",
    "                lamb_match=hyper[\"lamb_match\"], \n",
    "                lamb_nn=hyper[\"lamb_nn\"],\n",
    "                device=device,\n",
    "            )\n",
    "            h_loss = hinge_loss(z_rna, z_atac, nn_indices)\n",
    "        '''if epoch % 5 == 0:\n",
    "            print(f\"rna_loss: {rna_loss}\")\n",
    "            print(f\"atac_loss:{atac_loss}\")\n",
    "            print(f\"anc_loss: {anc_loss}\")\n",
    "            print(f\"hinge loss: {h_loss}\")'''\n",
    "\n",
    "        #loss functions for each modalities\n",
    "        train_loss = rna_loss + atac_loss + hyper[\"lamb_hinge\"] * h_loss\n",
    "        #train_loss = rna_loss + atac_loss\n",
    "        #train_loss = rna_loss + atac_loss + hyper[\"lamb_anc\"] * anc_loss\n",
    "        #rain_loss = rna_loss + atac_loss + hyper[\"lamb_anc\"] * anc_loss + h_loss\n",
    "        train_loss.backward()\n",
    "        nn.utils.clip_grad_norm_(netRNA.parameters(), max_norm=hyper[\"clip_grad\"])\n",
    "        nn.utils.clip_grad_norm_(netATAC.parameters(), max_norm=hyper[\"clip_grad\"])\n",
    "        opt_netRNA.step()\n",
    "        opt_netATAC.step()\n",
    "        train_losses.append(train_loss.item())\n",
    "    avg_train_loss = np.mean(train_losses)\n",
    "    if epoch % 5 == 0:\n",
    "        print(\"Epoch: \" + str(epoch) + \", train loss: \" + str(avg_train_loss))\n",
    "\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
